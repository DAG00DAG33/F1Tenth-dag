Here you have some ros2 foxy message deffinitions:

#std_msgs/msg/Header Message
builtin_interfaces/msg/Time stamp
string frame_id

#nav_msgs/msg/Path Message
std_msgs/msg/Header header
geometry_msgs/msg/PoseStamped[] poses

#geometry_msgs/msg/PoseStamped.msg
std_msgs/msg/Header header
geometry_msgs/msg/Pose pose

#geometry_msgs/msg/Pose Message
geometry_msgs/msg/Point position
geometry_msgs/msg/Quaternion orientation

#geometry_msgs/msg/Point Message
double x
double y
double z

#geometry_msgs/msg/Quaternion Message
double x=0.0
double y=0.0
double z=0.0
double w=1.0


Here you have an article on how to implement a pure pursuit algorithm.

This article will cover the steps for implementing a simple Pure Pursuit based controller for a skid steering robot on a flat surface, limiting the degrees of freedom to x, y and heading(yaw).

The controller will make use of the Pure Pursuit Algorithm to follow a desired trajectory. This is a good method to quickly implement a robust path/trajectory tracking controller for robots travelling at low speeds, where exact trajectory tracking is not required.

One can make use of optimal control methods like iLQR for better performance in those cases.

The aim of the controller is to determine the desired velocity of the robot given the current location of the robot and the trajectory to be followed.

The implementation discussed here is based on R. Craig Coulter’s work at the Robotics Institute, Carnegie Mellon University in January, 1992.
Robot ConstrainsPermalink

A skid steering robot cannot have a velocity in the lateral directon. However, due to wheel slippage, it can have a forward as well as angular velocity at any instant.
Pure PursuitPermalink

Pure Pursuit is a curvature based trajectory tracking controller. It works by calculating the curvature of the path to follow in order to reach from the current position to some goal position.

This goal position keeps on changing and is a point on the trajectory to be followed at a particular “lookahead distance” from it.

The following image explains the concept of lookahead distance and the arc to follow.

Geometry of Pure Pursuit Algorithm [1]

In the image above, we see that given a point at a particular location from the robot say at location (x,y) in the robot’s frame (the frame fixed on the robot). The point is at a distance l from the current location of the robot. Using a geometrical derivation, we can derive the radius of curvature of this arc as -

\gamma = \frac{2*x}{l^2}\

This is the radius of the path we want the system to follow in order to converge to the trajectory. We can see from the image that the arc is tangential to the current trajectory of the robot. Thus the kinematic constraints of the robot are not violated.

We see that the curvature is only dependent on the cross-track distance between the robot and the point and thus can be intutively thought of as a controller to minimize the cross track error.

In case of a trajectory, the location along the path at any point of time is known and thus the along track error can be used to determine the desired linear velocity utilising a PID controller. In case we want to follow a path, one method is to run a PID controller to reach the lookahead point or the velocity can be set to a constant value.

Given a V from the along-track error controller, since along the arc the linear and angular velocity are related by:

V= wr V=ω∗r

Thus the desired angular velocity can be determined as -

ω=Vr

ω=V∗γ

ω=2∗V∗xl2

This maps the cross-track error to the desired angular velocity of the robot. One should note that the only parameter that is tuned by the user is the lookahead distance, making it easy to tune.
ImplementationPermalink
1. Determine current location of the robotPermalink

The current location of the robot (x,y,\theta)in the world frame needs to be determined, this could come from the odometry sensor if the world frame is at the start of the path. In case one is using an absolute positioning method like a GPS, the world frame could be the “UTM” frame or any other world fixed frame.

    One should ensure that the robot and the world frame are provided in the same format i.e. ENU or NED format.

2. Find the point closest to the vehicle frame

The point on the trajectory closest to the robot needs to be determined. This step will depend on how the trajectory is provided, if the waypoints on the trajectory are sparsely provided, one can connect the closest two waypoints through a straight line and project the current location of the robot on it to determine the point on the trajectory closest to the robot. Alternatively, if the waypoints on the path/trajectory are quite dense, one can just use euclidean distance to compute the closest point.
3. Finding the goal point

The goal point is found by moving by one lookahead distance along the path/trajectory from the closest point identified before. This is the point we want to follow. However, this point is in the world frame and not in the robot’s frame.
4. Transforming the goal point to vehicle’s coordinates frame

Since the goal point is in world frame, it needs to be transformed to the robot’s frame. Accurate position and orientation estimate of the robot in the world frame is critical here. Yaw value is of special importance here as it is often noisy and can lead to errors.
5. Calculate controller outputPermalink

The linear velocity is determined using constant velocity

The angular velocity is computed using

ω=2∗V∗xl2

These desired linear and angular velocity is followed by a low level controller.

This was an article explaining how to implement a pure pursuit algorithm.

Please make a ros2 foxy node that implements this algorithm.

As input the node gets:
    -A pose message "/map_pose" with the car possition in the map frame
    -A path message "/targer_path" with the path the car has to follow. The poins are on the map frame

It needs to output:
    -An ackermannDriveStamped message "/drive" with the speed and steering the car needs to implement

Some parameters are:
    -The distance between the front and back wheels (wheelbase). By default it should be 0.3
    -The car frame name, by default it should be base_link

Make sure to continue doing laps after the path is completed. The path will loop closed.

Please make the ros2 foxy node in C++.


Here you have a header file for it:

#ifndef PURE_PURSUIT_NODE_HPP
#define PURE_PURSUIT_NODE_HPP

#include "rclcpp/rclcpp.hpp"
#include "std_msgs/msg/header.hpp"
#include "builtin_interfaces/msg/time.hpp"
#include "nav_msgs/msg/path.hpp"
#include "geometry_msgs/msg/pose_stamped.hpp"
#include "geometry_msgs/msg/pose.hpp"
#include "geometry_msgs/msg/point.hpp"
#include "geometry_msgs/msg/quaternion.hpp"
#include "ackermann_msgs/msg/ackermann_drive_stamped.hpp"

class PurePursuitNode : public rclcpp::Node
{
public:
  PurePursuitNode();

private:
  void currentPoseCallback(const geometry_msgs::msg::PoseStamped::SharedPtr msg);
  void targetPathCallback(const nav_msgs::msg::Path::SharedPtr msg);
  void calculateControl();
  double calculateDistance(const geometry_msgs::msg::Point& p1, const geometry_msgs::msg::Point& p2);
  geometry_msgs::msg::Point getLookaheadPoint(const geometry_msgs::msg::Point& closest_point, double lookahead_distance);
  geometry_msgs::msg::Point transformPoint(const geometry_msgs::msg::Point& point, const geometry_msgs::msg::PoseStamped& pose);
  double calculateCurvature(const geometry_msgs::msg::Point& point);

  // Member variables
  geometry_msgs::msg::PoseStamped current_pose_;
  nav_msgs::msg::Path target_path_;
  bool current_pose_received_;
  double wheelbase_;
  std::string car_frame_;

  // ROS 2 communication
  rclcpp::Subscription<geometry_msgs::msg::PoseStamped>::SharedPtr current_pose_sub_;
  rclcpp::Subscription<nav_msgs::msg::Path>::SharedPtr target_path_sub_;
  rclcpp::Publisher<ackermann_msgs::msg::AckermannDriveStamped>::SharedPtr drive_pub_;
};

#endif  // PURE_PURSUIT_NODE_HPP


